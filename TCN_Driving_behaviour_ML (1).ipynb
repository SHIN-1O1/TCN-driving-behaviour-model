{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece5c6f3-1082-458a-af44-54a1d5630659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, ReLU, Dropout, Dense, GlobalAvgPool1D\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6b279b-55a7-44a5-937b-b9883c2fc71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb6b8fd-a4c3-4bce-92fc-46b7f8dc40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_chunk_size(dataset_path, initial_chunk_size=100000):\n",
    "    chunk_size = initial_chunk_size\n",
    "    for chunk in pd.read_csv(dataset_path, chunksize=chunk_size):\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        print(f\"Memory Usage: {memory_usage}%\")\n",
    "        \n",
    "        if memory_usage > 90: \n",
    "            chunk_size = max(chunk_size // 2, 10000) \n",
    "            print(f\"Reducing chunk size to {chunk_size}\")\n",
    "        elif memory_usage < 80:  \n",
    "            chunk_size = min(chunk_size * 2, 500000)  \n",
    "            print(f\"Increasing chunk size to {chunk_size}\")\n",
    "        \n",
    "        process_chunk(chunk)\n",
    "        \n",
    "    return chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f9fc7c-a44e-4058-895c-a2f96d0a2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk):\n",
    "    processed_data.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06974caa-ab1b-4f1e-80e9-f400b130239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 52.7%\n",
      "Increasing chunk size to 200000\n",
      "Memory Usage: 52.9%\n",
      "Increasing chunk size to 400000\n",
      "Memory Usage: 52.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 52.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 53.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 54.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 55.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 56.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 57.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 58.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 59.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 60.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.1%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.2%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.3%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.4%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.5%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.6%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.7%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.8%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 61.9%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 62.0%\n",
      "Increasing chunk size to 500000\n",
      "Memory Usage: 62.1%\n",
      "Increasing chunk size to 500000\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/admin/OneDrive/Desktop/my folder/college work/projects and ideas/driving_behavior_large_dataset.csv\"\n",
    "processed_data = []\n",
    "optimal_chunk_size = get_optimal_chunk_size(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec5515d-f19d-4238-b944-98f9dd48ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Chunk Size: 500000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimal Chunk Size: {optimal_chunk_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69f4b9d-85b0-4091-a743-80492249d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(processed_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b74f0a-388b-4f9f-a990-5c815c15d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3159213-797c-4b81-ab14-96b3e5fb5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Event Label']) \n",
    "y = df['Event Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e47bce1-a3a2-4960-80b7-a453fd99ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Timestamp'] = pd.to_datetime(X['Timestamp'], errors='coerce').astype(int) / 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbfac789-4d04-4ffd-818b-2ab400fe3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2e3f9d-10c7-4736-8ac7-5602ef8b2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb1c281c-158a-421a-b29f-0f7918f786b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942759f7-a7e2-4439-b5a1-6f590226e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7ff113f-2874-4408-aee2-7275e2590d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2965e2a-a151-4865-b333-9c8216dfba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8cf4f16-593a-4a7f-8ecd-724a4d28c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1154 - val_accuracy: 0.9904 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0398 - val_accuracy: 0.9932 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0332 - val_accuracy: 0.9951 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0274 - val_accuracy: 0.9948 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.9970 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0209 - val_accuracy: 0.9959 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0196 - val_accuracy: 0.9967 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0186 - val_accuracy: 0.9974 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0182 - val_accuracy: 0.9971 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0175 - val_accuracy: 0.9956 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0170 - val_accuracy: 0.9972 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0165 - val_accuracy: 0.9966 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9972 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.9975 - val_loss: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0154 - val_accuracy: 0.9974 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0151 - val_accuracy: 0.9968 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0150 - val_accuracy: 0.9970 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0100 - val_accuracy: 0.9991 - val_loss: 0.0028 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.9990 - val_loss: 0.0029 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9990 - val_loss: 0.0029 - learning_rate: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9990 - val_loss: 0.0028 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9993 - val_loss: 0.0021 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.9993 - val_loss: 0.0020 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9992 - val_loss: 0.0021 - learning_rate: 4.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.9993 - val_loss: 0.0020 - learning_rate: 4.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 8.0000e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9996 - val_loss: 0.0018 - learning_rate: 8.0000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9996 - val_loss: 0.0018 - learning_rate: 8.0000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 8.0000e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9996 - val_loss: 0.0017 - learning_rate: 1.6000e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9995 - val_loss: 0.0017 - learning_rate: 1.6000e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 1.6000e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9995 - val_loss: 0.0017 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9997 - val_loss: 0.0017 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9996 - val_loss: 0.0017 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9996 - val_loss: 0.0017 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9995 - val_loss: 0.0018 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0744f1e2-8f84-4b50-92d9-5df13d02d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 873us/step - accuracy: 0.9996 - loss: 0.0017\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7138e542-beab-4d37-b283-fe5217bfc85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62500/62500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa83604f-b7f2-48cb-b307-5c2a635f7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    577206\n",
      "           1       1.00      1.00      1.00     39573\n",
      "           2       1.00      1.00      1.00   1279501\n",
      "           3       1.00      1.00      1.00     39662\n",
      "           4       1.00      1.00      1.00     64058\n",
      "\n",
      "    accuracy                           1.00   2000000\n",
      "   macro avg       1.00      1.00      1.00   2000000\n",
      "weighted avg       1.00      1.00      1.00   2000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c992eb2-3a1a-4fa3-8a53-4b68dcd483bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 576856      18     300      32       0]\n",
      " [     18   39505      43       0       7]\n",
      " [     21      47 1279291      85      57]\n",
      " [     16       0      21   39621       4]\n",
      " [      0       3      24       2   64029]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf21fa9-ff8a-4acb-94cf-7c6b8b25af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.saving\n",
    "keras.saving.save_model(model, \"driving_behavior_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66778c9-9ea5-4515-b36c-733967f0d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
